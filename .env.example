OPENAI_API_KEY=your-api-key
OLLAMA_HOST=http://ollama.server:11434
VLLM_HOST=http://vllm.server:8000
VLLM_API_KEY=your-vllm-api-key
# do not change this TORCH_HOME variable
TORCH_HOME=./pretrained_models